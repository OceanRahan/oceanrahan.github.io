<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AmarDoctor | HCI Case Study</title>
  <link rel="stylesheet" href="css/style_portfolio.css">
   <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">


</head>

<body>

<header class="site-header">
  <div class="header-inner">
    <div class="nav">
  <a href="index.html">
  <i class="fa fa-home"></i> Home
</a>
</div>
    <h1 class="site-title">AmarDoctor</h1>
    <p class="site-subtitle">
      Designing an AI-Driven, Multilingual Digital Health Platform for Underserved Communities
    </p>
    <i class="fa-solid fa-file-pdf" style="height:20px;"></i>
            <a href="images/AmarDoctor_extended_case_study.pdf" target="_blank" style="color:#E9E3DF; font-size:18px;"><strong>Extended Case Study</strong></a>
                
  </div>

</header>

<main class="case-study">

  <!-- Overview -->
  <section class="section overview">
    <div class="text-block">
      <h2>Project Overview</h2>
      <p style="font-size: 25px;">
        AmarDoctor is an AI-driven, voice-interactive healthcare platform designed to support primary care triage and everyday health decision-making for underserved Bengali-speaking
        populations.
      </p>
      <p class="meta" style="font-size:14pt;">
        <strong>Role:</strong> End-to-end designer & developer<br>
        <strong>Focus:</strong> Human-centered AI, accessibility, conversational interfaces
      </p>
    </div>
  </section>

  <!-- Problem -->
  <section class="section split interactive v1">
    <div>
      <h2>Problem Context</h2>
      <p style="font-size: 15pt;">
        Existing digital health tools fail many users due to language barriers,
        rigid medical terminology, cognitively demanding menu-based navigation, and lack of technology that helps in daily decision making.
      </p>
      <ul>
        <li style="font-size: 13pt; color: black"><strong>Language Barriers</strong>: Colloquial symptom expressions not supported.</li>
        <li style="font-size: 13pt; color: black"><strong>Limited Health Literacy</strong>: Uncertainty about which specialist to consult.</li>
        <li style="font-size: 13pt;color: black"><strong>Fragmented Medical History</strong>: Paper-based records are often lost, damaged, or hard to maintain over long-term care.</li>
        <li style="font-size: 13pt; color: black"><strong>Digital Unfamiliarity</strong>: Form-driven interfaces impose high cognitive load.</li>
        <li style="font-size: 13pt; color: black"><strong>Lack of Dietary Guidance</strong>: Chronic disease management requires informed dietary intake, which is often unavailable due to limited professional guidance.</li>
      </ul>      
      <figure class="image-block" style="width:65%; margin-left:120px;">
      <img src="images/ai_img4.png" alt="Healthcare access challenges">
    </figure>
     
    </div>
    <figure class="image-block" style="width:100%">
      <img src="images/ai_img_1.png" alt="Healthcare access challenges">
    </figure>
     
  </section>

  <!-- Design Strategy -->
  <section class="section split reverse interactive v2">
    <div class="text-block">
      <h2>Design Strategy</h2>
      <p style="font-size: 15pt;">
        <i class="fa fa-arrow-right"></i>
        Redesigned the interaction from menu navigation to conversational dialogue,
        allowing users to communicate health concerns using natural language.
      </p>
       <p style="font-size: 15pt;">
        <i class="fa fa-arrow-right"></i>Priotizied Accessibility through voice input, reduced text density, and progressive disclosure of information.
      </p>
        <figure class="image-block" style="width:60%; margin-left:250px;">
      <img src="images/ss.png" alt="Conversational interface flow">
    </figure>
    </div>

    
  </section>

  <!-- KEY MODULES -->
<section class="section">
  <h2>Key System Modules</h2>
</section>

<!-- MODULE 1 -->
<section class="section split interactive v3">
  <div class="text-block">
    <h3>Symptom Assessment</h3>
    <p style="font-size:12pt;">
      <i class="fa fa-arrow-right"></i> Users describe health concerns using natural, colloquial language rather than predefined clinical categories, generates meaningful outputs for physicians, streamlining their workflows. 
    </p>
    <p style="font-size:12pt;">
      <i class="fa fa-arrow-right"></i> Design emphasis was placed on reducing cognitive load, supporting voice-first interaction, and maintaining transparency in system responses.
    </p>
  </div>

  <div class="media-block">
    <video controls muted preload="metadata" poster="images/poster1.png">
      <source src="images/symptom_checker.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <p class="caption">Symptom Assessment Through Triaging and Clinical Decision Support </p>
  </div>
</section>


<!-- MODULE 2 -->
<section class="section split interactive v4">
  <div class="text-block">
    <h3>Dietary Guidance & Lifestyle Support</h3>
    <p> <i class="fa fa-arrow-right"></i> This module provides culturally contextual dietary recommendations based on health conditions and locally available foods.
    </p>
    <p>
      <i class="fa fa-arrow-right"></i>Multimodal interaction (text, images, and voice) supports users with varying
      literacy levels.
    </p>
  </div>

  <div class="media-block">
    <video controls muted preload="metadata" poster="images/poster2.png">
      <source src="images/food_guidance.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <p class="caption">Personalized dietary guidance for everyday health decisions</p>
  </div>
</section>


<!-- MODULE 3 -->
<section class="section split reverse interactive v5">
  <div class="media-block">
    <video controls muted preload="metadata" poster="images/digitization.png">
      <source src="images/digitization.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
      <p class="caption">Medical Documents Digitization Workflow </p>
  </div>
  <div class="text-block">
    <h3>Medical Report Digitization</h3>
    <p>
      <i class="fa fa-arrow-right"></i>Patients frequently carry handwritten prescriptions and diagnostic reports
      that are difficult to preserve and reference over time.
    </p>
    <p>
       <i class="fa fa-arrow-right"></i>This module converts paper-based medical documents into structured digital records, enabling longitudinal access and reducing reliance on patient memory.
    </p>

  </div>

  
</section>

  <!-- Evaluation -->
  <section class="section split interactive v6">
  <div class="text-block">
    <h2>Evaluation & Outcomes</h2>
    <div class="image-block" style="width:75%; margin-left:150px;">
    <img src="images/evaluation2.png" alt="Evaluation summary visualization">
    
  </div>
  </figure>
    <h3 style="font-size:17pt;">Interaction Engagement</h3>
    <ul>
    <li style="font-size:14pt;">Over a 28-day period, the platform was used by <strong>13,388</strong> users, generating <strong>158,858</strong> interaction events.</li>
    <li style="font-size:14pt;">Among all features, the dynamic triage and conversational chatbot modules showed the highest depth of engagement.</li>
  </ul>
 

    <h3 style="font-size:17pt;">Module-level behavior</h3>
    <ul><li>Users interacting with the dynamic triage module averaged <strong>7.51</strong> interactions per user, indicating sustained multi-step engagement.</li>

    <li>The chatbot module showed <strong>5.56</strong> interactions per user, reflecting repeated conversational use.</li>
    <li>In contrast, static or form-based screens averaged <strong>~1.5</strong> interactions per user, suggesting single-pass task completion.</li>
  </ul>

    <h3 style="font-size:17pt;">Interpretation</h3>
    <ul>
      <li>These patterns indicate that conversational and adaptive interfaces better support users’ health-seeking behaviors than traditional menu-based designs.</p>
        <li>Higher interaction depth suggests reduced cognitive friction and stronger alignment with users’ mental models, particularly for users with limited health literacy.</li>
      </li>
    </ul>
    <div class="image-block" style="width:65%; margin-left:200px;">
    <figure>
    <img src="images/evaluation.png" alt="Evaluation summary visualization">
    <p><strong>Figure</strong>: Average interactions per user across system modules.
Conversational and adaptive modules (dynamic triage, chatbot) show 3-5 times deeper engagement than static screens.</p>
</figure>

  </div>
  </div>
   
</section>


  <!-- Limitation -->
  <section class="section split interactive v7">
  <div class="text-block">
    <h2>Limitations & Future Work</h2>
    <p style="font-size:14pt;">This evaluation relied primarily on interaction logs and vignette-based diagnostic validation. While these methods capture real-world usage patterns and technical reliability, they do not fully explain users’ motivations, decision-making processes, or experiences of trust.

    <p style="font-size:14pt;">Engagement metrics reflect interaction frequency rather than interaction quality. Future work will combine log-based analysis with usability testing, interviews, and participatory design methods to better understand how users interpret system feedback and make health decisions.</p>

    <p style="font-size:14pt;">Diagnostic validation was conducted using clinically constructed vignettes rather than real-world clinical outcomes. Ongoing work will explore clinician-in-the-loop evaluation and longitudinal studies to assess real-world effectiveness and ethical deployment.</p>
</div>
</section>

  <!-- Reflection -->
  <section class="section reflection">
    <h2>Reflection</h2>
    <p style="font-size:17pt; color: black">
      <strong>AmarDoctor</strong> project reinforced that engagement and trust in health AI are driven less by technical sophistication alone and more by how well interaction models align with users’ language and cognitive patterns. Interpreting real-world engagement data alongside diagnostic validation shaped my interest in mixed-methods HCI evaluation and strengthened my goal of advancing human-centered AI for healthcare.
    </p>
  </section>
</section>

</main>

<footer class="site-footer">
  <p>© Nazmun Nahar | HCI Portfolio</p>
</footer>

</body>
</html>
